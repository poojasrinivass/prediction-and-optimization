{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from keras import metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path, sep): \n",
    "    balance_data = pd.read_csv( path, \n",
    "    sep= sep, header = None) \n",
    "      \n",
    "#     Printing the dataset shape \n",
    "#     print (\"Dataset Lenght: \", len(balance_data)) \n",
    "#     print (\"Dataset Shape: \", balance_data.shape) \n",
    "#     Printing the dataset obseravtions \n",
    "#     print (\"Dataset: \",balance_data.head()) \n",
    "    return balance_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "#     distributed data into input parameters X and predicitons Y\n",
    "#     data = np.asarray(data)\n",
    "    data = data.loc[1:, :]\n",
    "    X = data.values[:, :-3]\n",
    "    Y = data.values[:, -3:]\n",
    "\n",
    "#     splitting into training and testing datasets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n",
    "    \n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    Y_train = np.asarray(Y_train, dtype=np.float32)\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    Y_test = np.asarray(Y_test, dtype=np.float32)\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 20) (45000, 3) (5000, 20) (5000, 3)\n"
     ]
    }
   ],
   "source": [
    "path = \"./not16nm_Delays_process_temp_pvdd_cqloadNEWLOAD.csv\"\n",
    "path1 = \"./AND2_16nm_stat00.csv\"\n",
    "data = import_data(path, ',')\n",
    "train_x, train_y, test_x, test_y = split_dataset(data)\n",
    "print(train_x.shape,train_y.shape,test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "#path = \"./not16nm_Delays_process_temp_pvdd_cqloadNEWLOAD.csv\"\n",
    "#data = import_data(path, ',')\n",
    "\n",
    "#data = data.loc[1:, :]\n",
    "#X = data.values[:, :-3]\n",
    "#Y = data.values[:, -3:]\n",
    "\n",
    "#X_train = np.asarray(X, dtype=np.float32)\n",
    "#Y_train = np.asarray(Y, dtype=np.float32)\n",
    "    \n",
    "def NN(X_train,Y_train):\n",
    "# Initialize the constructor\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an input layer and one hidden\n",
    "    model.add(Dense(10, activation='tanh', input_shape=(20,), kernel_initializer='normal'))\n",
    "\n",
    "    model.add(Dense(5, activation='tanh', kernel_initializer='normal'))\n",
    "\n",
    "    # Add an output layer \n",
    "    model.add(Dense(3, kernel_initializer='normal'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # #set early stopping monitor so the model stops training when it won't improve anymore\n",
    "    # early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "    #train model\n",
    "    model.fit(X_train, Y_train, validation_split=0.2, epochs=15, verbose=2)\n",
    "    return { \"model\" : model }\n",
    "\n",
    "# results = model.fit(train_x, train_y, epochs=2, batch_size = 500, validation_data = (test_x, test_y))\n",
    "#print(\"Test-Accuracy:\", np.mean(results.history[\"val_acc\"])))\n",
    "\n",
    "#test\n",
    "# test_y_predictions = model.predict(test_x)\n",
    "# print(test_y_predictions)\n",
    "\n",
    "# Accuracy\n",
    "# print(\"test error: {}%\".format(np.mean((test_y_predictions - test_y)**2) * 100))\n",
    "\n",
    "# scores = model.evaluate(x=test_x, y=test_y, batch_size=None, verbose=2, sample_weight=None, steps=None)\n",
    "\n",
    "# print('Test loss:', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression for Mulitple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMM(train_x,train_y):\n",
    "    model1 = MultiOutputRegressor(SVR(kernel='rbf', C=1, gamma=0.1, epsilon=.1))\n",
    "    predict_Y = model1.fit(train_x, train_y).predict(test_x)\n",
    "    print(predict_Y.shape,test_y.shape)\n",
    "#     score = np.square(np.sum(np.subtract(test_y, predict_Y)))*100/5000\n",
    "    score_1 = mean_squared_error(test_y,predict_Y)\n",
    "    #scores = model1.evaluate(x=test_x, y=test_y, batch_size=None, verbose=2, sample_weight=None, steps=None)\n",
    "    #score1 = predict_Y.score(test_x, test_y)\n",
    "#     print(score_1)\n",
    "    return { \"model\" : model1, \"mse\" : score_1 }\n",
    "#{ ( 1 / N ) * Σ [ (xi - x) * (yi - y) ] / (σx * σy ) }2\n",
    "#x = np.subtract(predict_Y, np.mean(predict_Y))\n",
    "#y = np.subtract(test_y, np.mean(test_y))\n",
    "#v =np.multiply(np.std(predict_Y),np.std(test_y))\n",
    "#u = np.multiply(v,5000)\n",
    "#score2 = np.square(np.sum(np.multiply(x,y))/u)\n",
    "\n",
    "#print(score2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(train_x,train_y):\n",
    "    model2 = MultiOutputRegressor(LinearRegression())\n",
    "    model2.fit(train_x, train_y)\n",
    "    predicty = model2.predict(test_x)\n",
    "    #score2 = model1.score(test_x, test_y)\n",
    "    score1 = mean_squared_error(predicty, test_y) \n",
    "    #score3 = r2_score(predicty, predicty) \n",
    "#     score2 = np.square(np.sum(np.subtract(test_y, predicty)))*100/5000\n",
    "#     print(score1,score2)\n",
    "    return { \"model\" : model2, \"mse\" : score1 } \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(train_x,train_y,maxdepth1):\n",
    "    #max_depth1 = 2\n",
    "    #max_depth2 = 10\n",
    "\n",
    "    model3 =  RandomForestRegressor(n_estimators=100, max_depth=max_depth1,\n",
    "                                    random_state=2)\n",
    "    #model4 =  RandomForestRegressor(n_estimators=100, max_depth=max_depth2,\n",
    "     #                               random_state=2)\n",
    "\n",
    "    model3.fit(train_x, train_y)\n",
    "    #model4.fit(train_x, train_y)\n",
    "\n",
    "    predict_y3= model3.predict(test_x)\n",
    "    #predict_y4= model4.predict(test_x)\n",
    "\n",
    "    #score3_1 = model3.score(test_x, test_y)\n",
    "    score3_2 = mean_squared_error(predict_y3, test_y)\n",
    "#     score3_3 = np.square(np.sum(np.subtract(test_y, predict_y3)))*100/5000\n",
    "\n",
    "    #score4_1 = model4.score(test_x, test_y)\n",
    "    #score4_2 = mean_squared_error(predict_y4, test_y)\n",
    "    #score4_3 = np.square(np.sum(np.subtract(test_y, predict_y4)))*100/5000\n",
    "\n",
    "#     print(score3_2,score3_3)\n",
    "    return { \"model\" : model3, \"mse\" : score3_2 }\n",
    "    #print(score4_2,score4_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTree(train_x,train_y,maxdepth):    \n",
    "    #maxdepth= 2\n",
    "    model5 = DecisionTreeRegressor(max_depth=maxdepth)\n",
    "    model5.fit(train_x, train_y)\n",
    "\n",
    "    predict_y5 = model5.predict(test_x)\n",
    "\n",
    "    #score5_1 = model3.score(test_x, test_y)\n",
    "    score5_2 = mean_squared_error(predict_y5, test_y)\n",
    "#     /score5_3 = np.square(np.sum(np.subtract(test_y, predict_y5)))*100/5000\n",
    "\n",
    "#     print(score5_2, score5_3)\n",
    "    return { \"model\" : model5, \"mse\" : score5_2 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelret(mod,train_x,train_y):\n",
    "    if(mod==\"SVM\"):\n",
    "        ret = SVMM(train_x,train_y)\n",
    "    elif(mod==\"LR\"):\n",
    "        ret = LR(train_x,train_y)\n",
    "    elif(mod==\"NN\"):\n",
    "        ret = NN(train_x,train_y)\n",
    "    elif(mod==\"RF\"):\n",
    "        ret = RF(train_x,train_y,2)\n",
    "    elif(mod == \"DT\"):\n",
    "        ret = DecisionTree(train_x,train_y,2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6c169471024b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DT\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "model = Modelret(\"DT\",train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.000e+00  3.900e+01  8.000e-01  1.919e-08  8.091e-10  1.200e-08\n",
      "   1.268e-09  9.824e+22  1.106e+16  2.619e+25  3.106e+26  2.447e-08\n",
      "   8.091e-10  1.200e-08  1.268e-09  9.824e+22  2.619e+25  1.106e+16\n",
      "   3.106e+26  2.447e-08  1.413e-15]\n",
      " [ 2.000e+00 -2.800e+01  8.100e-01  2.100e-08  7.722e-10  1.149e-08\n",
      "   1.383e-09  9.635e+22  1.096e+16  2.759e+25  2.919e+26  2.610e-08\n",
      "   7.722e-10  1.149e-08  1.383e-09  9.635e+22  2.759e+25  1.096e+16\n",
      "   2.919e+26  2.610e-08  1.579e-15]\n",
      " [ 3.000e+00  1.150e+02  7.400e-01  2.000e-08  8.205e-10  1.217e-08\n",
      "   1.340e-09  1.017e+23  1.081e+16  2.666e+25  3.132e+26  2.659e-08\n",
      "   8.205e-10  1.217e-08  1.340e-09  1.017e+23  2.666e+25  1.081e+16\n",
      "   3.132e+26  2.659e-08  6.130e-16]\n",
      " [ 4.000e+00  6.000e+00  8.400e-01  1.905e-08  8.250e-10  1.170e-08\n",
      "   1.383e-09  1.023e+23  1.078e+16  2.914e+25  3.039e+26  2.680e-08\n",
      "   8.250e-10  1.170e-08  1.383e-09  1.023e+23  2.914e+25  1.078e+16\n",
      "   3.039e+26  2.680e-08  2.182e-15]\n",
      " [ 5.000e+00  6.600e+01  7.200e-01  1.980e-08  8.297e-10  1.180e-08\n",
      "   1.424e-09  9.644e+22  1.071e+16  2.964e+25  2.958e+26  2.715e-08\n",
      "   8.297e-10  1.180e-08  1.424e-09  9.644e+22  2.964e+25  1.071e+16\n",
      "   2.958e+26  2.715e-08  1.414e-15]]\n",
      "[[1.085e-11 1.509e-11 1.090e-11 1.440e-11 1.054e-11 1.350e-11]\n",
      " [1.232e-11 1.695e-11 1.222e-11 1.618e-11 1.163e-11 1.519e-11]\n",
      " [7.664e-12 1.012e-11 7.812e-12 9.472e-12 7.579e-12 8.593e-12]\n",
      " [1.315e-11 1.896e-11 1.318e-11 1.825e-11 1.280e-11 1.732e-11]\n",
      " [1.119e-11 1.533e-11 1.120e-11 1.463e-11 1.080e-11 1.370e-11]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, gate):\n",
    "    if gate == \"AND3\":\n",
    "        data = import_data('./AND3/AND_3_delay_16nm.csv', ',')\n",
    "        data.head()\n",
    "        data = data.values[1:, :]\n",
    "        # print(data[:5, :])\n",
    "        X = data[:, :-6]\n",
    "        Y = data[:, -6:]\n",
    "        X_del = np.asarray(X, dtype=np.float32)\n",
    "        Y_del = np.asarray(Y, dtype=np.float32)\n",
    "#         print(X[:5, :])\n",
    "#         print(Y[:5, :])\n",
    "        model_and3 = Modelret(model, X_del, Y_del)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
