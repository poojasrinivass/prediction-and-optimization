{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from keras import metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path, sep): \n",
    "    balance_data = pd.read_csv( path, \n",
    "    sep= sep, header = None) \n",
    "      \n",
    "#     Printing the dataset shape \n",
    "#     print (\"Dataset Lenght: \", len(balance_data)) \n",
    "#     print (\"Dataset Shape: \", balance_data.shape) \n",
    "#     Printing the dataset obseravtions \n",
    "#     print (\"Dataset: \",balance_data.head()) \n",
    "    return balance_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "#     distributed data into input parameters X and predicitons Y\n",
    "#     data = np.asarray(data)\n",
    "    data = data.loc[1:, :]\n",
    "    X = data.values[:, :-3]\n",
    "    Y = data.values[:, -3:]\n",
    "\n",
    "#     splitting into training and testing datasets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n",
    "    \n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    Y_train = np.asarray(Y_train, dtype=np.float32)\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    Y_test = np.asarray(Y_test, dtype=np.float32)\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 20) (45000, 3) (5000, 20) (5000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pooja/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    }
   ],
   "source": [
    "path = \"./not16nm_Delays_process_temp_pvdd_cqloadNEWLOAD.csv\"\n",
    "path1 = \"./AND2_16nm_stat00.csv\"\n",
    "data = import_data(path1, ',')\n",
    "train_x, train_y, test_x, test_y = split_dataset(data)\n",
    "print(train_x.shape,train_y.shape,test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      " - 1s - loss: 2.0942e-06 - acc: 0.8608 - val_loss: 4.5953e-15 - val_acc: 1.0000\n",
      "Epoch 2/15\n",
      " - 1s - loss: 3.6354e-15 - acc: 0.9992 - val_loss: 3.3425e-15 - val_acc: 1.0000\n",
      "Epoch 3/15\n",
      " - 1s - loss: 4.0715e-15 - acc: 0.9600 - val_loss: 3.6992e-15 - val_acc: 1.0000\n",
      "Epoch 4/15\n",
      " - 1s - loss: 4.9759e-15 - acc: 0.8904 - val_loss: 6.7154e-15 - val_acc: 0.0000e+00\n",
      "Epoch 5/15\n",
      " - 1s - loss: 1.5447e-09 - acc: 0.5640 - val_loss: 2.2626e-11 - val_acc: 0.0000e+00\n",
      "Epoch 6/15\n",
      " - 1s - loss: 4.3175e-09 - acc: 0.4800 - val_loss: 8.1654e-10 - val_acc: 1.0000\n",
      "Epoch 7/15\n",
      " - 1s - loss: 4.6880e-09 - acc: 0.4488 - val_loss: 1.7297e-09 - val_acc: 0.0000e+00\n",
      "Epoch 8/15\n",
      " - 1s - loss: 3.9239e-09 - acc: 0.4392 - val_loss: 8.7460e-10 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      " - 1s - loss: 3.8770e-09 - acc: 0.4576 - val_loss: 3.2359e-09 - val_acc: 0.0000e+00\n",
      "Epoch 10/15\n",
      " - 1s - loss: 3.4679e-09 - acc: 0.4560 - val_loss: 6.8489e-09 - val_acc: 0.0000e+00\n",
      "Epoch 11/15\n",
      " - 1s - loss: 2.8845e-09 - acc: 0.4656 - val_loss: 1.1069e-11 - val_acc: 0.0000e+00\n",
      "Epoch 12/15\n",
      " - 1s - loss: 2.6063e-09 - acc: 0.4336 - val_loss: 5.3291e-12 - val_acc: 1.0000\n",
      "Epoch 13/15\n",
      " - 1s - loss: 2.5308e-09 - acc: 0.3600 - val_loss: 5.7037e-10 - val_acc: 0.0000e+00\n",
      "Epoch 14/15\n",
      " - 1s - loss: 2.0826e-09 - acc: 0.3672 - val_loss: 4.8159e-09 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      " - 1s - loss: 1.9652e-09 - acc: 0.3328 - val_loss: 1.9404e-10 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f7b0906d8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "path = \"./not16nm_Delays_process_temp_pvdd_cqloadNEWLOAD.csv\"\n",
    "data = import_data(path, ',')\n",
    "\n",
    "data = data.loc[1:, :]\n",
    "X = data.values[:, :-3]\n",
    "Y = data.values[:, -3:]\n",
    "\n",
    "X_train = np.asarray(X, dtype=np.float32)\n",
    "Y_train = np.asarray(Y, dtype=np.float32)\n",
    "    \n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer and one hidden\n",
    "model.add(Dense(10, activation='tanh', input_shape=(20,), kernel_initializer='normal'))\n",
    "\n",
    "model.add(Dense(5, activation='tanh', kernel_initializer='normal'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(3, kernel_initializer='normal'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# #set early stopping monitor so the model stops training when it won't improve anymore\n",
    "# early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "#train model\n",
    "model.fit(X_train, Y_train, validation_split=0.2, epochs=15, verbose=2)\n",
    "\n",
    "# results = model.fit(train_x, train_y, epochs=2, batch_size = 500, validation_data = (test_x, test_y))\n",
    "#print(\"Test-Accuracy:\", np.mean(results.history[\"val_acc\"])))\n",
    "\n",
    "#test\n",
    "# test_y_predictions = model.predict(test_x)\n",
    "# print(test_y_predictions)\n",
    "\n",
    "# Accuracy\n",
    "# print(\"test error: {}%\".format(np.mean((test_y_predictions - test_y)**2) * 100))\n",
    "\n",
    "# scores = model.evaluate(x=test_x, y=test_y, batch_size=None, verbose=2, sample_weight=None, steps=None)\n",
    "\n",
    "# print('Test loss:', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression for Mulitple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3) (5000, 3)\n",
      "2.0837096681216334e-07 1.4273820108344197e-13\n"
     ]
    }
   ],
   "source": [
    "model1 = MultiOutputRegressor(SVR(kernel='rbf', C=1, gamma=0.1, epsilon=.1))\n",
    "predict_Y = model1.fit(train_x, train_y).predict(test_x)\n",
    "print(predict_Y.shape,test_y.shape)\n",
    "score = np.square(np.sum(np.subtract(test_y, predict_Y)))*100/5000\n",
    "score_1 = mean_squared_error(test_y,predict_Y)\n",
    "#scores = model1.evaluate(x=test_x, y=test_y, batch_size=None, verbose=2, sample_weight=None, steps=None)\n",
    "#score1 = predict_Y.score(test_x, test_y)\n",
    "print(score,score_1)\n",
    "#{ ( 1 / N ) * Σ [ (xi - x) * (yi - y) ] / (σx * σy ) }2\n",
    "#x = np.subtract(predict_Y, np.mean(predict_Y))\n",
    "#y = np.subtract(test_y, np.mean(test_y))\n",
    "#v =np.multiply(np.std(predict_Y),np.std(test_y))\n",
    "#u = np.multiply(v,5000)\n",
    "#score2 = np.square(np.sum(np.multiply(x,y))/u)\n",
    "\n",
    "#print(score2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.822176e-15 2.9485552888175446e-12\n"
     ]
    }
   ],
   "source": [
    "model2 = MultiOutputRegressor(LinearRegression())\n",
    "model2.fit(train_x, train_y)\n",
    "predicty = model2.predict(test_x)\n",
    "#score2 = model1.score(test_x, test_y)\n",
    "score1 = mean_squared_error(predicty, test_y) \n",
    "#score3 = r2_score(predicty, predicty) \n",
    "score2 = np.square(np.sum(np.subtract(test_y, predicty)))*100/5000\n",
    "print(score1,score2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.826320559994989e-15 3.0253157063654915e-12\n",
      "3.826320559994989e-15 3.0253157063654915e-12\n"
     ]
    }
   ],
   "source": [
    "max_depth1 = 2\n",
    "max_depth2 = 10\n",
    "\n",
    "model3 =  RandomForestRegressor(n_estimators=100, max_depth=max_depth1,\n",
    "                                random_state=2)\n",
    "model4 =  RandomForestRegressor(n_estimators=100, max_depth=max_depth2,\n",
    "                                random_state=2)\n",
    "\n",
    "model3.fit(train_x, train_y)\n",
    "model4.fit(train_x, train_y)\n",
    "\n",
    "predict_y3= model3.predict(test_x)\n",
    "predict_y4= model4.predict(test_x)\n",
    "\n",
    "#score3_1 = model3.score(test_x, test_y)\n",
    "score3_2 = mean_squared_error(predict_y3, test_y)\n",
    "score3_3 = np.square(np.sum(np.subtract(test_y, predict_y3)))*100/5000\n",
    "\n",
    "#score4_1 = model4.score(test_x, test_y)\n",
    "score4_2 = mean_squared_error(predict_y4, test_y)\n",
    "score4_3 = np.square(np.sum(np.subtract(test_y, predict_y4)))*100/5000\n",
    "\n",
    "print(score3_2,score3_3)\n",
    "print(score4_2,score4_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.826310416725325e-15 3.0101006213076296e-12\n"
     ]
    }
   ],
   "source": [
    "maxdepth= 2\n",
    "model5 = DecisionTreeRegressor(max_depth=maxdepth)\n",
    "model5.fit(train_x, train_y)\n",
    "\n",
    "predict_y5 = model5.predict(test_x)\n",
    "\n",
    "#score5_1 = model3.score(test_x, test_y)\n",
    "score5_2 = mean_squared_error(predict_y5, test_y)\n",
    "score5_3 = np.square(np.sum(np.subtract(test_y, predict_y5)))*100/5000\n",
    "\n",
    "print(score5_2, score5_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
